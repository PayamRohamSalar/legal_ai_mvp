# ----------------------------------------
# GENERAL APPLICATION SETTINGS
# ----------------------------------------
# Environment mode: 'development', 'staging', or 'production'
ENVIRONMENT=development
# Set to True for development mode (enables debug endpoints and detailed errors)
DEBUG=True
# A secret key for signing sessions and tokens.
# Generate a secure key with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY="a_very_secret_key_for_development_change_me"

# ----------------------------------------
# API & WEB SERVER CONFIGURATION
# ----------------------------------------
# Host and port for the FastAPI server (inside Docker, 0.0.0.0 is required)
API_HOST=0.0.0.0
API_PORT=8000
# Comma-separated list of allowed origins for CORS
CORS_ORIGINS="http://localhost:3000,http://localhost:8501"

# ----------------------------------------
# DATABASE (PostgreSQL)
# ----------------------------------------
# These values should match the ones in docker-compose.yml for development
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=legal_ai_user
POSTGRES_PASSWORD=development_password
POSTGRES_DB=legal_ai

# ----------------------------------------
# VECTOR DATABASE (ChromaDB)
# ----------------------------------------
# Hostname for the ChromaDB server container
CHROMA_HOST=chromadb
CHROMA_PORT=8000
# Default collection name for storing legal document vectors
CHROMA_COLLECTION=legal_documents

# ----------------------------------------
# CACHING (Redis)
# ----------------------------------------
# Hostname for the Redis server container
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=

# ----------------------------------------
# LLM & AI CONFIGURATION
# ----------------------------------------
# Active LLM provider: 'google_gemini', 'openai', or 'local'
LLM_PROVIDER=google_gemini

# --- API Keys (only the one for the active provider is required) ---
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
# OPENAI_API_KEY="YOUR_OPENAI_API_KEY_HERE"

# --- Model settings ---
# Specific model name for the selected provider
GEMINI_MODEL=gemini-1.5-flash-latest
# Controls the creativity of the model (0.0 to 1.0)
LLM_TEMPERATURE=0.1
# Maximum number of tokens in the generated response
LLM_MAX_TOKENS=2048

# ----------------------------------------
# EMBEDDING MODEL CONFIGURATION
# ----------------------------------------
# The sentence-transformer model used for creating vector embeddings
EMBEDDING_MODEL=paraphrase-multilingual-mpnet-base-v2